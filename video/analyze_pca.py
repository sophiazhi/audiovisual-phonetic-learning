import numpy as np
import argparse
from sklearn.decomposition import PCA
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from joblib import dump # , load
import json
from torchvision.io import read_video
import torch
import os
from tqdm import tqdm
import video_library
import sklearn

def parse_args():
    parser = argparse.ArgumentParser(description='Parse arguments for video feature extraction')
    
    # parser.add_argument('train_json', help='Path to json list of training videos') # input file name
    parser.add_argument('model_name', help='Path to output model pkl file') # model file name
    parser.add_argument('--video_fn', default='video_transform_7797', help='video transform function name')
    parser.add_argument('--n_components', type=int, default=20, help='Number of PCA components')
    parser.add_argument('--video_corpus', default='/om2/user/szhi/corpora/buckeye_synthetic_video')

    args = parser.parse_args()
    return args

def read_train_list(train_json):
    with open(train_json, 'r') as f:
        train_list = json.load(f)
    return train_list

def process_videos(train_list, video_transform, video_corpus):
    video_data = []
    for video_name in tqdm(train_list):
        if not os.path.exists(os.path.splitext(os.path.join(video_corpus, video_name))[0] + ".mp4"):
            print(f"Missing {os.path.splitext(video_name)[0]}")
            continue
        video_info = read_video(os.path.splitext(os.path.join(video_corpus, video_name))[0] + ".mp4", pts_unit='sec')
        video_tensor = video_info[0] # BHWC, torch.Size([742, 1080, 1920, 3])
        video_tensor = video_transform(video_tensor)
        video_data.append(video_tensor)
    
    all_video_tensor = torch.cat(video_data, dim=0)
    all_video_ndarray = all_video_tensor.detach().cpu().numpy()
    np.save('video/pretrain.npy', all_video_ndarray)
    return all_video_ndarray

def train(train_data, model_name, n_components):
    pca = Pipeline(steps=[    
        ('scaling',StandardScaler()),
        ('pca',PCA(n_components=20))
        ]) # PCA(n_components=n_components)
    pca.fit(train_data)
    dump(pca, model_name)
    return pca

if __name__ == '__main__':
    args = parse_args()
    
    train_list = read_train_list("be1375fy/pretrain.json")

    video_transform = getattr(video_library, args.video_fn)
    # train_data = process_videos(train_list, video_transform, args.video_corpus)
    train_data = np.load('video/pretrain.npy')
    model = train(train_data, args.model_name, args.n_components)

    print(np.cumsum(model['pca'].explained_variance_ratio_))
    '''
    [0.47078019 0.64855686 0.72473425 0.78869663 0.83850395 0.86464186
    0.88430103 0.9016809  0.91204774 0.92023426 0.9268714  0.93246998
    0.93643378 0.94010082 0.94364375 0.94699817 0.94971163 0.95218054
    0.95426273 0.95626489]
    [[ 1.88369296e+03 -9.65707628e+02  1.83972212e+02  4.88667262e+02
    6.80410384e+02  1.52542245e+02 -2.84946997e+02  5.73576822e+01
    -3.90925113e+01 -2.11875756e+02  5.86804769e+01  2.18619982e+01
    -2.07604872e+01 -2.31885113e+01 -3.90037011e+00 -4.53717009e+01
    2.77450712e+01  8.47812860e+00 -8.08277765e-01  2.90034924e+01]
    [ 1.88146133e+03 -9.63295307e+02  1.82567710e+02  4.87912573e+02
    6.82298039e+02  1.47457078e+02 -2.83492723e+02  5.91036507e+01
    -4.02362696e+01 -2.15688006e+02  5.64126159e+01  1.50924247e+01
    -2.65835690e+01 -2.12493101e+01 -8.84815524e+00 -4.33948549e+01
    3.17748192e+01  1.18863116e+01 -1.16682285e+00  2.65112545e+01]
    [ 1.88485521e+03 -9.64814221e+02  1.80946415e+02  4.87527756e+02
    6.82431811e+02  1.50133564e+02 -2.83949469e+02  5.75303683e+01
    -3.99114527e+01 -2.12468534e+02  6.11277268e+01  1.97027630e+01
    -2.17670585e+01 -2.38146855e+01 -7.40769769e+00 -4.49230172e+01
    3.17277651e+01  1.01589721e+01 -2.72245763e-01  2.71838705e+01]
    [ 1.88042954e+03 -9.63945648e+02  1.83346419e+02  4.85668463e+02
    6.81503928e+02  1.45781757e+02 -2.84812972e+02  5.76612293e+01
    -4.12771633e+01 -2.13959530e+02  5.65061377e+01  1.87412083e+01
    -2.37995357e+01 -2.16046979e+01 -8.22646714e+00 -4.45568112e+01
    3.02881634e+01  1.25190288e+01 -5.50928130e-01  2.69968248e+01]
    [ 1.88129450e+03 -9.60276691e+02  1.78586201e+02  4.86789231e+02
    6.77728613e+02  1.43950982e+02 -2.88672788e+02  5.25772104e+01
    -3.39977783e+01 -2.07500633e+02  5.16531291e+01  1.93311578e+01
    -2.56522522e+01 -2.28610753e+01 -8.98244887e+00 -4.41893811e+01
    3.01479302e+01  9.85885293e+00  2.21678057e+00  2.97193706e+01]
    [ 1.87995226e+03 -9.61866943e+02  1.87147619e+02  4.83417910e+02
    6.82560670e+02  1.44160117e+02 -2.83507678e+02  5.81748043e+01
    -3.60754497e+01 -2.10514900e+02  5.71998231e+01  2.10655622e+01
    -2.17550746e+01 -2.31304487e+01 -6.60028456e+00 -4.61696681e+01
    2.91215645e+01  1.30849193e+01  4.47097049e-01  2.62417203e+01]
    [ 1.87851058e+03 -9.65033332e+02  1.87148034e+02  4.83552343e+02
    6.80223041e+02  1.44695734e+02 -2.82924885e+02  5.71406923e+01
    -3.45526703e+01 -2.11199691e+02  5.66425453e+01  2.05547342e+01
    -2.17732862e+01 -2.26586121e+01 -8.49002642e+00 -4.70101592e+01
    3.22593667e+01  1.44542418e+01  2.38848634e+00  2.30382414e+01]
    [ 1.87488010e+03 -9.65149121e+02  1.83784921e+02  4.79541650e+02
    6.80369601e+02  1.43324059e+02 -2.76957644e+02  6.31144981e+01
    -3.47212416e+01 -2.15867165e+02  5.49289540e+01  2.39335113e+01
    -2.33303084e+01 -2.57399834e+01 -1.26029645e+01 -5.36345771e+01
    3.34826919e+01  1.62001912e+01  3.76556525e+00  2.44390196e+01]
    [ 1.86888124e+03 -9.58220369e+02  1.76779344e+02  4.87177167e+02
    6.72060123e+02  1.43746979e+02 -2.79573013e+02  5.83247060e+01
    -3.07964084e+01 -2.10478870e+02  4.73724756e+01  3.16594675e+01
    -1.46314742e+01 -2.12257759e+01 -1.36716651e+01 -5.01809379e+01
    2.97257708e+01  9.38379759e+00  1.41628135e+00  2.21367793e+01]
    [ 1.85166549e+03 -9.50973716e+02  1.63313739e+02  4.88440968e+02
    6.62613635e+02  1.47899665e+02 -2.60118680e+02  6.67706769e+01
    -3.26376095e+01 -2.03986736e+02  4.76634514e+01  4.23959754e+01
    -8.36685755e+00 -1.73247799e+01 -2.12988064e+01 -5.23782727e+01
    3.37892125e+01  1.14581593e+01  2.20606740e+00  1.25035836e+01]]'''

    '''[0.29146118 0.48348497 0.5894442  0.66167793 0.72422389 0.75933472
    0.7898454  0.81638366 0.83296719 0.84717916 0.85793798 0.86718319
    0.87480981 0.88142285 0.88724057 0.89286548 0.89716177 0.90100463
    0.90460457 0.90742483]
    [[111.31621527 -72.96830053  77.57286781 -35.82653864  14.59021522
    10.33252181 -17.42148274   2.56220362 -28.52115268  -1.16862312
    1.99810449  -0.61608821  -4.18715197  -7.79676882   9.56415228
    0.39568438   5.54618909  -2.73949398   0.65268463   0.30124408]
    [111.21230751 -71.95488742  77.05871375 -36.57758554  13.71890007
    9.52468188 -18.66953232   2.826692   -28.29410033  -0.92401536
    0.28843782  -0.13682122  -3.71149342  -7.525809    10.01201857
    0.22352911   5.77507948  -2.87582443   1.01227619   1.73930914]
    [111.98625776 -72.31311033  76.99215861 -36.01949584  13.77909252
    9.5941516  -18.43043429   3.06003757 -28.26794242  -1.52900392
    0.59912212  -0.34836944  -3.78915469  -7.82428657   9.95964282
    0.44045162   5.9744361   -2.82840649   1.03869806   1.45540671]
    [111.08751389 -72.35346493  76.84578052 -36.51301934  13.97406727
    9.29591482 -18.24649257   2.92937296 -28.10426972  -1.58689385
    0.66457314  -0.15180466  -3.38930274  -7.61916389  10.0255231
    0.6208016    5.80071546  -2.87974279   1.16180384   1.7552724 ]
    [111.2285594  -72.17892048  76.69077712 -36.61466416  14.07527839
    9.39057944 -17.88851073   2.93926528 -27.91584702  -1.85628162
    0.41622309  -0.36280968  -3.33531591  -7.34485446   9.72293985
    0.69896312   5.82780781  -2.93696979   1.50116011   1.43628914]
    [111.01898737 -72.37200844  76.68121378 -36.50147705  14.13664177
    9.25445102 -18.21522176   3.37827993 -28.22594253  -1.65962524
    0.66231799  -0.52310416  -3.49556992  -7.67945234   9.65751988
    0.77082726   5.74825665  -2.9091264    1.08571967   1.71501142]
    [110.96005606 -72.42928601  76.6595263  -36.48861719  14.11623062
    9.25293042 -18.2000689    3.30310245 -28.16615316  -1.59241896
    0.65053475  -0.47125426  -3.45366624  -7.70406258   9.63208311
    0.78187598   5.75710442  -2.87342572   1.1109939    1.74027887]
    [110.40999157 -72.2696208   76.0151753  -36.32928541  13.80420675
    9.21033897 -19.07354414   2.94894205 -29.02368867  -1.62172748
    0.90171494  -0.96308243  -3.62317294  -8.1377351    9.69505389
    1.41442024   6.05288807  -2.43989106   1.30488159   0.84529906]
    [110.41649188 -71.79399529  76.05356952 -36.49292702  13.16974985
    9.4502888  -18.02950686   2.6189187  -28.43605945  -1.51907843
    1.42075762  -1.01431855  -3.12131142  -7.39979845   9.01075758
    1.74000205   5.6606438   -2.38607607   1.12056005   1.27221624]
    [110.04938266 -70.40553079  75.2430156  -35.60216986  12.13347865
    8.98628394 -18.26723362   2.90580231 -28.60380373  -1.40998662
    1.725587    -1.20270729  -2.35253839  -7.84542908   8.29959616
    1.38880943   5.41276896  -2.08515381   1.68319026   0.74039677]]'''
    print(model.transform(train_data[:10]))